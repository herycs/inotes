# Hadoop概述

## 背景

### 需要解决的难点

- 读取速度：多磁盘并行读取
- 硬件故障：备份，冗余磁盘阵列
- 任务需求数据量大：分析需要多个盘的数据结合使用

### 特征

- 数据本地化
- 无共享

Hadoop提供了可靠的存储分析系统，核心两部分HDFS（Hadoop Distributed FileSystem)实现存储，MapReduce实现分析处理

> MapReduce 将磁盘读写问题进行抽象，并转换为数据集，计算由map和reduce两部分组成
>
> 每次查询需要处理整个数据集

### B树与MapReduce

少量的数据更新B树性能更好（受限于寻址的比例）

更新大部分数据时MapReduce更合适，适用于少更新，多读取的数据操作

### 网格计算

高性能计算（High Performance Computing, HPC）和网格计算（Grid Computing）组织致力于研究大数据计算

让程序员仅从键-值角度考虑任务的执行

MapReduce负责处理部分数据失效，进程之间的协调

MapReduce负责控制 mapper 的输出结果传递给reducer的过程

### 设计目标

服务于短时间可以执行完成的任务，运行于内部通过高速网格连接的单一数据中心内

### 数据分片

将MapReduce输入数据划分为等长的数据块

- 处理时间缩短：并行处理的时间会缩短
- 分片大小：一般将其设置为HDFS的一个块的大小是适合大多数作业的
- 数据本地化优化：在存储有输入数据的节点上运行map任务可以获得最佳性能

map结果存入磁盘而非HDFS为何？

map结果一般是中间结果，reduce处理后才是最终结果，这时才有必要存入HDFS实现备份，直接存中间结果有些小题大做

### 数据块

Hadoop数据块（默认64MB）为何如此大？

<u>最小化寻址开销</u>，块足够大，这时磁盘传输时间明显大于定位时间，这样传输由多个块组成的文件的时间取决于磁盘传输速率

为何使用抽象块？

简化了存储子系统的设计

## 集群

### 节点

Hadoop集群有两类节点，namenode, datanode

并以管理者-工作者的模式进行

- namenode 管理文件系统的命名空间，维护着文件系统树及整颗树内所有文件和目录，这些信息以两个文件存储于本地磁盘上（命名空间镜像文件 & 编辑日志文件）

- datanode：工作节点，存储检索数据块，定期向namenode发送本地存储的块的列表

### NameNode

备份机制：

- 备份：组成文件系统元数据持久状态的文件
- 辅助：
    1. 运行辅助namenode，定期通过编辑日志合并命名空间镜像，防止编辑日志文件过大
    2. 保存命名空间镜像副本

## 相关应用

### Pig

为大数据集处理提供了更高程度的抽象

### Hive

构建在HDFS上的数据仓库框架

### HBase

构建在HDFS上的面向列的分布式数据库

### Zookeeper

Hadoop的分布式协调服务

### Sqoop

允许用户从关系型数据库中抽取数据到非关系型数据库





